{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Q55-U4nQTI",
        "outputId": "3c49a449-54e3-409f-af0b-e9efe412542a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 's-vae-pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nicola-decao/s-vae-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s-vae-pytorch/setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwNDWF3DnX5s",
        "outputId": "dafd6201-7fb0-4802-dac1-2854ae147351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing hyperspherical_vae.egg-info/PKG-INFO\n",
            "writing dependency_links to hyperspherical_vae.egg-info/dependency_links.txt\n",
            "writing requirements to hyperspherical_vae.egg-info/requires.txt\n",
            "writing top-level names to hyperspherical_vae.egg-info/top_level.txt\n",
            "reading manifest file 'hyperspherical_vae.egg-info/SOURCES.txt'\n",
            "writing manifest file 'hyperspherical_vae.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/hyperspherical_vae-0.1.1-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing hyperspherical_vae-0.1.1-py3.9.egg\n",
            "Removing /usr/local/lib/python3.9/dist-packages/hyperspherical_vae-0.1.1-py3.9.egg\n",
            "Copying hyperspherical_vae-0.1.1-py3.9.egg to /usr/local/lib/python3.9/dist-packages\n",
            "hyperspherical-vae 0.1.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/hyperspherical_vae-0.1.1-py3.9.egg\n",
            "Processing dependencies for hyperspherical-vae==0.1.1\n",
            "Searching for numpy==1.22.4\n",
            "Best match: numpy 1.22.4\n",
            "Adding numpy 1.22.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.9 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for scipy==1.10.1\n",
            "Best match: scipy 1.10.1\n",
            "Adding scipy 1.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for torch==2.0.0+cu118\n",
            "Best match: torch 2.0.0+cu118\n",
            "Adding torch 2.0.0+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for triton==2.0.0\n",
            "Best match: triton 2.0.0\n",
            "Adding triton 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for networkx==3.0\n",
            "Best match: networkx 3.0\n",
            "Adding networkx 3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for sympy==1.11.1\n",
            "Best match: sympy 1.11.1\n",
            "Adding sympy 1.11.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for filelock==3.10.7\n",
            "Best match: filelock 3.10.7\n",
            "Adding filelock 3.10.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for lit==16.0.0\n",
            "Best match: lit 16.0.0\n",
            "Adding lit 16.0.0 to easy-install.pth file\n",
            "Installing lit script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for cmake==3.25.2\n",
            "Best match: cmake 3.25.2\n",
            "Adding cmake 3.25.2 to easy-install.pth file\n",
            "Installing cmake script to /usr/local/bin\n",
            "Installing cpack script to /usr/local/bin\n",
            "Installing ctest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for MarkupSafe==2.1.2\n",
            "Best match: MarkupSafe 2.1.2\n",
            "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Finished processing dependencies for hyperspherical-vae==0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s-vae-pytorch/examples/mnist.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdD2p2UuncbM",
        "outputId": "3d2fc492-75b1-4308-ce82-908af7680943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/s-vae-pytorch/examples/mnist.py\", line 11, in <module>\n",
            "    from hyperspherical_vae.distributions import VonMisesFisher\n",
            "ModuleNotFoundError: No module named 'hyperspherical_vae'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys as sys\n",
        "print(sys.path)\n",
        "\n",
        "sys.path.append(\"/content/s-vae-pytorch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY6M5Ecyy-q_",
        "outputId": "ea456e31-0979-4dd4-e340-d8dae51dbc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.9/dist-packages/IPython/extensions', '/root/.ipython', '/content/s-vae-pytorch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "from collections import defaultdict\n",
        "\n",
        "from hyperspherical_vae.distributions import VonMisesFisher\n",
        "from hyperspherical_vae.distributions import HypersphericalUniform"
      ],
      "metadata": {
        "id": "FjGjPkwMyfYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain the batch free single cell data"
      ],
      "metadata": {
        "id": "Zf7c-zNhxnPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz -O data/pbmc3k_filtered_gene_bc_matrices.tar.gz\n",
        "!cd data; tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz\n",
        "!mkdir write "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFvEoepoxcsw",
        "outputId": "d46cff17-b843-4c39-bc79-d0e75eb3bbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2023-04-06 06:13:46--  http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz\n",
            "Resolving cf.10xgenomics.com (cf.10xgenomics.com)... 104.18.1.173, 104.18.0.173, 2606:4700::6812:1ad, ...\n",
            "Connecting to cf.10xgenomics.com (cf.10xgenomics.com)|104.18.1.173|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz [following]\n",
            "--2023-04-06 06:13:46--  https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz\n",
            "Connecting to cf.10xgenomics.com (cf.10xgenomics.com)|104.18.1.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7621991 (7.3M) [application/x-tar]\n",
            "Saving to: ‘data/pbmc3k_filtered_gene_bc_matrices.tar.gz’\n",
            "\n",
            "data/pbmc3k_filtere 100%[===================>]   7.27M  9.52MB/s    in 0.8s    \n",
            "\n",
            "2023-04-06 06:13:48 (9.52 MB/s) - ‘data/pbmc3k_filtered_gene_bc_matrices.tar.gz’ saved [7621991/7621991]\n",
            "\n",
            "mkdir: cannot create directory ‘write’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_mtx(filename, dtype='int32'):\n",
        "    from scipy.io import mmread\n",
        "\n",
        "    x = mmread(filename).astype(dtype)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "XYVLbXshyC12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_path = \"/content/data/filtered_gene_bc_matrices/hg19/matrix.mtx\"\n",
        "X = read_mtx(matrix_path)\n",
        "print(X.shape)\n",
        "X = X.transpose().todense()\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JXdxVLVyELl",
        "outputId": "c1c8d8c5-3f2e-4301-aff3-225b703a3582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32738, 2700)\n",
            "(2700, 32738)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(X > 1))\n",
        "print(np.sum(X == 1))\n",
        "print(np.sum(X < 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMoUaCJX6lVV",
        "outputId": "2949db82-e6d7-442f-ef2d-38071209bb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "689509\n",
            "1597375\n",
            "86105716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(X)"
      ],
      "metadata": {
        "id": "IACVlUVTA4I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to(torch.float32)"
      ],
      "metadata": {
        "id": "lZFtd2NMBTMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Multiply(nn.Module):\n",
        "  def __init__(self, library_size):\n",
        "    super(Multiply, self).__init__()\n",
        "    self.library_size = library_size\n",
        "  \n",
        "  def forward(self, x):\n",
        "      x *= self.library_size\n",
        "      return x"
      ],
      "metadata": {
        "id": "oyh-f_OHD89B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelVAE(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, h_dim, z_dim, activation=F.relu, distribution='normal', x=None):\n",
        "        \"\"\"\n",
        "        ModelVAE initializer\n",
        "        :param h_dim: dimension of the hidden layers\n",
        "        :param z_dim: dimension of the latent representation\n",
        "        :param activation: callable activation function\n",
        "        :param distribution: string either `normal` or `vmf`, indicates which distribution to use\n",
        "        \"\"\"\n",
        "        super(ModelVAE, self).__init__()\n",
        "        \n",
        "        self.z_dim, self.activation, self.distribution = z_dim, activation, distribution\n",
        "        \n",
        "        # 2 hidden layers encoder\n",
        "        # Old dimension for MNIST\n",
        "        # self.fc_e0 = nn.Linear(784, h_dim * 2)\n",
        "        # New dimension of input\n",
        "        self.fc_e0 = nn.Linear(32738, h_dim * 2)\n",
        "        self.fc_e1 = nn.Linear(h_dim * 2, h_dim)\n",
        "\n",
        "        if self.distribution == 'normal':\n",
        "            # compute mean and std of the normal distribution\n",
        "            self.fc_mean = nn.Linear(h_dim, z_dim)\n",
        "            self.fc_var =  nn.Linear(h_dim, z_dim)\n",
        "        elif self.distribution == 'vmf':\n",
        "            # compute mean and concentration of the von Mises-Fisher\n",
        "            self.fc_mean = nn.Linear(h_dim, z_dim)\n",
        "            self.fc_var = nn.Linear(h_dim, 1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "            \n",
        "        # 2 hidden layers decoder\n",
        "        self.fc_d0 = nn.Linear(z_dim, h_dim)\n",
        "        self.fc_d1 = nn.Linear(h_dim, h_dim * 2)\n",
        "        # Old dimension for MNIST\n",
        "        # self.fc_logits = nn.Linear(h_dim * 2, 784)\n",
        "        # New dimension of input\n",
        "        self.fc_logits = nn.Linear(h_dim * 2, 32738)\n",
        "        self.mu_layer = nn.Linear(h_dim * 2, 32738)\n",
        "        self.var_layer = nn.Linear(h_dim * 2, 32738)\n",
        "\n",
        "        # self.library_size = torch.sum(x[0: 64,:], dim=1, keepdim=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # 2 hidden layers encoder\n",
        "        x = self.activation(self.fc_e0(x))\n",
        "        x = self.activation(self.fc_e1(x))\n",
        "        \n",
        "        if self.distribution == 'normal':\n",
        "            # compute mean and std of the normal distribution\n",
        "            z_mean = self.fc_mean(x)\n",
        "            z_var = F.softplus(self.fc_var(x))\n",
        "        elif self.distribution == 'vmf':\n",
        "            # compute mean and concentration of the von Mises-Fisher\n",
        "            z_mean = self.fc_mean(x)\n",
        "            z_mean = z_mean / z_mean.norm(dim=-1, keepdim=True)\n",
        "            # the `+ 1` prevent collapsing behaviors\n",
        "            z_var = F.softplus(self.fc_var(x)) + 1\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "        \n",
        "        return z_mean, z_var\n",
        "        \n",
        "    def decode(self, z):\n",
        "        \n",
        "        x = self.activation(self.fc_d0(z))\n",
        "        x = self.activation(self.fc_d1(x))\n",
        "        # x = self.fc_logits(x)\n",
        "        mu = F.softmax(self.mu_layer(x))\n",
        "        # mu *= self.library_size\n",
        "        # multiply = Multiply(library_size)\n",
        "        # mu.requires_grad= True\n",
        "        # mu = multiply(mu)\n",
        "        sigma_square = F.softplus(self.var_layer(x))\n",
        "        sigma_square = torch.sum(sigma_square, dim=0)\n",
        "        return mu, sigma_square\n",
        "        \n",
        "    def reparameterize(self, z_mean, z_var):\n",
        "        if self.distribution == 'normal':\n",
        "            q_z = torch.distributions.normal.Normal(z_mean, z_var)\n",
        "            p_z = torch.distributions.normal.Normal(torch.zeros_like(z_mean), torch.ones_like(z_var))\n",
        "        elif self.distribution == 'vmf':\n",
        "            q_z = VonMisesFisher(z_mean, z_var)\n",
        "            p_z = HypersphericalUniform(self.z_dim - 1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "\n",
        "        return q_z, p_z\n",
        "        \n",
        "    def forward(self, x): \n",
        "        z_mean, z_var = self.encode(x)\n",
        "        q_z, p_z = self.reparameterize(z_mean, z_var)\n",
        "        z = q_z.rsample()\n",
        "        # x_ = self.decode(z)\n",
        "        mu_, sigma_square_ = self.decode(z)\n",
        "        return (z_mean, z_var), (q_z, p_z), z, mu_, sigma_square_"
      ],
      "metadata": {
        "id": "WXxvQsN9zYPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(model, x, n=10):\n",
        "    \"\"\"\n",
        "    :param model: model object\n",
        "    :param optimizer: optimizer object\n",
        "    :param n: number of MC samples\n",
        "    :return: MC estimate of log-likelihood\n",
        "    \"\"\"\n",
        "    # Old dimension for MNIST\n",
        "    # z_mean, z_var = model.encode(x.reshape(-1, 784))\n",
        "    z_mean, z_var = model.encode(x)\n",
        "    q_z, p_z = model.reparameterize(z_mean, z_var)\n",
        "    z = q_z.rsample(torch.Size([n]))\n",
        "    x_mb_ = model.decode(z)\n",
        "\n",
        "    log_p_z = p_z.log_prob(z)\n",
        "\n",
        "    if model.distribution == 'normal':\n",
        "        log_p_z = log_p_z.sum(-1)\n",
        "\n",
        "    log_p_x_z = -nn.BCEWithLogitsLoss(reduction='none')(x_mb_, x.reshape(-1, 784).repeat((n, 1, 1))).sum(-1)\n",
        "\n",
        "    log_q_z_x = q_z.log_prob(z)\n",
        "\n",
        "    if model.distribution == 'normal':\n",
        "        log_q_z_x = log_q_z_x.sum(-1)\n",
        "\n",
        "    return ((log_p_x_z + log_p_z - log_q_z_x).t().logsumexp(-1) - np.log(n)).mean()"
      ],
      "metadata": {
        "id": "gke1WXT5160W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood_nb(x, mu, sigma, eps=1e-16):\n",
        "\n",
        "    log_mu_sigma = torch.log(mu + sigma + eps)\n",
        "\n",
        "    ll = torch.lgamma(x + sigma) - torch.lgamma(sigma) - \\\n",
        "        torch.lgamma(x + 1) + sigma * torch.log(sigma + eps) - \\\n",
        "        sigma * log_mu_sigma + x * torch.log(mu + eps) - x * log_mu_sigma\n",
        "\n",
        "    return ll"
      ],
      "metadata": {
        "id": "dCVaZl4R3g9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library_size = None\n",
        "def train(model, optimizer):\n",
        "    # for i, (x_mb, y_mb) in enumerate(train_loader):\n",
        "    for i in range(0, X.shape[0], 64):\n",
        "    # for x in X:\n",
        "            if i+64 < X.shape[0]:\n",
        "              x = X[i: i+64, :]\n",
        "            else:\n",
        "              x = X[i:, :]\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # dynamic binarization\n",
        "            # x_mb = (x_mb > torch.distributions.Uniform(0, 1).sample(x_mb.shape)).float()\n",
        "\n",
        "            # _, (q_z, p_z), _, x_mb_ = model(x_mb.reshape(-1, 784))\n",
        "            global library_size\n",
        "            library_size = torch.sum(x, dim=1, keepdim=True)\n",
        "            (z_mean, z_var), (q_z, p_z), _, mu, sigma_square = model(x)\n",
        "            # loss_recon = nn.BCEWithLogitsLoss(reduction='none')(x_reconstructed, x).sum(-1).mean()\n",
        "            # loss_recon = log_likelihood(x, z_mean, z_var)\n",
        "            mu = mu * library_size\n",
        "            loss_recon = log_likelihood_nb(\n",
        "                x,\n",
        "                mu,\n",
        "                sigma_square,\n",
        "            ).sum(-1).mean()\n",
        "          \n",
        "            if model.distribution == 'normal':\n",
        "                loss_KL = torch.distributions.kl.kl_divergence(q_z, p_z).sum(-1).mean()\n",
        "            elif model.distribution == 'vmf':\n",
        "                loss_KL = torch.distributions.kl.kl_divergence(q_z, p_z).mean()\n",
        "            else:\n",
        "                raise NotImplemented\n",
        "\n",
        "            loss = loss_recon + loss_KL\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "eF8UqZkH2vnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden dimension and dimension of latent space\n",
        "H_DIM = 128\n",
        "Z_DIM = 5\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "# normal VAE\n",
        "modelN = ModelVAE(h_dim=H_DIM, z_dim=Z_DIM, distribution='normal', x=X)\n",
        "optimizerN = optim.Adam(modelN.parameters(), lr=1e-3)\n",
        "\n",
        "print('##### Normal VAE #####')\n",
        "\n",
        "# training for 1 epoch\n",
        "train(modelN, optimizerN)\n",
        "\n",
        "# test\n",
        "# test(modelN, optimizerN)\n",
        "\n",
        "print()\n",
        "\n",
        "# hyper-spherical  VAE\n",
        "modelS = ModelVAE(h_dim=H_DIM, z_dim=Z_DIM + 1, distribution='vmf')\n",
        "optimizerS = optim.Adam(modelS.parameters(), lr=1e-3)\n",
        "\n",
        "print('##### Hyper-spherical VAE #####')\n",
        "\n",
        "# training for 1 epoch\n",
        "train(modelS, optimizerS)\n",
        "\n",
        "# test\n",
        "# test(modelS, optimizerS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ZW8lsRAnFj",
        "outputId": "bc57e49e-bd63-4e73-947b-1c4b675f80b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Normal VAE #####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-71ac4c9d4f99>:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  mu = F.softmax(self.mu_layer(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##### Hyper-spherical VAE #####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/distributions/distribution.py:51: UserWarning: <class 'hyperspherical_vae.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byueprTFBDp6",
        "outputId": "956dfc67-2da4-4f91-ff8c-7030885cf85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}