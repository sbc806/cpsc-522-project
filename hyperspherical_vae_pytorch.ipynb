{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Q55-U4nQTI",
        "outputId": "6a0cdbb6-53f2-4dc8-a1b2-72f13f86bbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 's-vae-pytorch'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 107 (delta 0), reused 5 (delta 0), pack-reused 98\u001b[K\n",
            "Receiving objects: 100% (107/107), 29.69 KiB | 7.42 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nicola-decao/s-vae-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python s-vae-pytorch/setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwNDWF3DnX5s",
        "outputId": "ddd7ef87-c000-4a1e-b301-500854d1463c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating hyperspherical_vae.egg-info\n",
            "writing hyperspherical_vae.egg-info/PKG-INFO\n",
            "writing dependency_links to hyperspherical_vae.egg-info/dependency_links.txt\n",
            "writing requirements to hyperspherical_vae.egg-info/requires.txt\n",
            "writing top-level names to hyperspherical_vae.egg-info/top_level.txt\n",
            "writing manifest file 'hyperspherical_vae.egg-info/SOURCES.txt'\n",
            "reading manifest file 'hyperspherical_vae.egg-info/SOURCES.txt'\n",
            "writing manifest file 'hyperspherical_vae.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying hyperspherical_vae.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/hyperspherical_vae-0.1.1-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing hyperspherical_vae-0.1.1-py3.9.egg\n",
            "Copying hyperspherical_vae-0.1.1-py3.9.egg to /usr/local/lib/python3.9/dist-packages\n",
            "Adding hyperspherical-vae 0.1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/hyperspherical_vae-0.1.1-py3.9.egg\n",
            "Processing dependencies for hyperspherical-vae==0.1.1\n",
            "Searching for numpy==1.22.4\n",
            "Best match: numpy 1.22.4\n",
            "Adding numpy 1.22.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.9 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for scipy==1.10.1\n",
            "Best match: scipy 1.10.1\n",
            "Adding scipy 1.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for torch==2.0.0+cu118\n",
            "Best match: torch 2.0.0+cu118\n",
            "Adding torch 2.0.0+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for triton==2.0.0\n",
            "Best match: triton 2.0.0\n",
            "Adding triton 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for networkx==3.0\n",
            "Best match: networkx 3.0\n",
            "Adding networkx 3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for sympy==1.11.1\n",
            "Best match: sympy 1.11.1\n",
            "Adding sympy 1.11.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for filelock==3.10.7\n",
            "Best match: filelock 3.10.7\n",
            "Adding filelock 3.10.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for lit==16.0.0\n",
            "Best match: lit 16.0.0\n",
            "Adding lit 16.0.0 to easy-install.pth file\n",
            "Installing lit script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for cmake==3.25.2\n",
            "Best match: cmake 3.25.2\n",
            "Adding cmake 3.25.2 to easy-install.pth file\n",
            "Installing cmake script to /usr/local/bin\n",
            "Installing cpack script to /usr/local/bin\n",
            "Installing ctest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for MarkupSafe==2.1.2\n",
            "Best match: MarkupSafe 2.1.2\n",
            "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.9/dist-packages\n",
            "Finished processing dependencies for hyperspherical-vae==0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9oQgpMRJTN3",
        "outputId": "1cae9102-f660-4678-cd70-44d0c2a22bd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.9.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from scanpy) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from scanpy) (23.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.4.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.12.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.1.1)\n",
            "Collecting anndata>=0.7.4\n",
            "  Downloading anndata-0.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn>=0.3.10\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.0)\n",
            "Requirement already satisfied: h5py>=3 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.10.1)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.2.2)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.13.5)\n",
            "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.56.4)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.9/dist-packages (from scanpy) (8.3.1)\n",
            "Collecting session-info\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (5.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.41.0->scanpy) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.41.0->scanpy) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->scanpy) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy->scanpy) (1.16.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stdlib_list\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.4->scanpy) (3.15.0)\n",
            "Building wheels for collected packages: umap-learn, session-info, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82830 sha256=f5892ee25c91d67feab569966c6318c43aca65b184bf010ce3d26144d8984619\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/3e/1c/596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8042 sha256=fddd6e5f297d8e0928a6f3aa9e9d01e1b26be7915502e44e755858e398c54587\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/fc/2e/00ca60bac7954b84907efd41baa9b4853500eaeec4228410c6\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55509 sha256=0793778c980198c834a930daf144ee56518b6e3ca214ab8808668a0768c950db\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/89/cc/59ab91ef5b21dc2ab3635528d7d227f49dfc9169905dcb959d\n",
            "Successfully built umap-learn session-info pynndescent\n",
            "Installing collected packages: stdlib_list, session-info, pynndescent, anndata, umap-learn, scanpy\n",
            "Successfully installed anndata-0.8.0 pynndescent-0.5.8 scanpy-1.9.3 session-info-1.0.0 stdlib_list-0.8.0 umap-learn-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install bbknn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojvzqSBcQOLf",
        "outputId": "7e37d4a6-086a-4b8f-f601-f040223c772e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bbknn\n",
            "  Downloading bbknn-1.5.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pynndescent in /usr/local/lib/python3.9/dist-packages (from bbknn) (0.5.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from bbknn) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from bbknn) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from bbknn) (1.22.4)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (from bbknn) (0.29.34)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from bbknn) (1.10.1)\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.1.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.0/648.0 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.9/dist-packages (from bbknn) (0.5.3)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.9/dist-packages (from pynndescent->bbknn) (0.56.4)\n",
            "Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.9/dist-packages (from pynndescent->bbknn) (0.39.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from pynndescent->bbknn) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->bbknn) (3.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from umap-learn->bbknn) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.2->pynndescent->bbknn) (67.6.1)\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.1-cp39-cp39-linux_x86_64.whl size=582311 sha256=a139cbbe8a03c9d3f9feaaeb6164642530c12f59cc0975a050d0540c3921d598\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/7d/31/9a9a4993d085bc85bee21946bce94cd5906ce99730f5467e57\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy, bbknn\n",
            "Successfully installed annoy-1.17.1 bbknn-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys as sys\n",
        "print(sys.path)\n",
        "\n",
        "sys.path.append(\"/content/s-vae-pytorch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY6M5Ecyy-q_",
        "outputId": "5cae4b7a-332e-44b6-f8ad-786b344696db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.9/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os as os\n",
        "import scanpy as sc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "from collections import defaultdict\n",
        "\n",
        "from hyperspherical_vae.distributions import VonMisesFisher\n",
        "from hyperspherical_vae.distributions import HypersphericalUniform"
      ],
      "metadata": {
        "id": "FjGjPkwMyfYY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(filename):\n",
        "  adata = sc.read_h5ad(filename)\n",
        "  return adata"
      ],
      "metadata": {
        "id": "dBlNLreAJcXY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"./drive/MyDrive/immune_cell_dataset/\"\n",
        "# data can be myeloid, b_cells, or t_cells\n",
        "data = \"t_cells\"\n",
        "file_path = os.path.join(file_path, data)\n",
        "if data == \"myeloid\":\n",
        "  filename = \"myeloid.h5ad\"\n",
        "elif data == \"b_cells\":\n",
        "  filename = \"b-cells.h5ad\"\n",
        "else:\n",
        "  filename = \"t-cells.h5ad\"\n",
        "file_path = os.path.join(file_path, filename)\n",
        "\n",
        "adata = read_data(file_path)"
      ],
      "metadata": {
        "id": "4JXdxVLVyELl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adata.X is the cell by gene matrix\n",
        "# myeloid is 51,52 x 36,601\n",
        "# t_cells is 216,611 x 36,601\n",
        "# b_cells is 54,934 x 36,601\n",
        "# dtype is float 32\n",
        "adata.X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTajBgmgLkmO",
        "outputId": "50eef0bd-62dc-4cdb-f3a0-af9d11523b42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216611, 36601)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "n-oHwvK3VT4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select highly variable genes\n",
        "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
        "adata = adata[:, adata.var.highly_variable]\n",
        "print(adata.X.shape)\n",
        "# Scale to unit variance and zero mean\n",
        "sc.pp.scale(adata)"
      ],
      "metadata": {
        "id": "LzRxSvlnRGa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5726c94-ca0a-4289-a57c-6a0b52e57e10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(216611, 1252)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n",
            "  view_to_actual(adata)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get rid of batch effects"
      ],
      "metadata": {
        "id": "OrOcAtxcOGlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bbknn\n",
        "\n",
        "bbknn.ridge_regression(adata, batch_key=['Chemistry'])"
      ],
      "metadata": {
        "id": "vHftXwxDQZEW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperspherical VAE"
      ],
      "metadata": {
        "id": "tFBbd96oQccA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelVAE(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, h_dim, z_dim, activation=F.relu, distribution='normal', x=None):\n",
        "        \"\"\"\n",
        "        ModelVAE initializer\n",
        "        :param h_dim: dimension of the hidden layers\n",
        "        :param z_dim: dimension of the latent representation\n",
        "        :param activation: callable activation function\n",
        "        :param distribution: string either `normal` or `vmf`, indicates which distribution to use\n",
        "        \"\"\"\n",
        "        super(ModelVAE, self).__init__()\n",
        "        \n",
        "        self.z_dim, self.activation, self.distribution = z_dim, activation, distribution\n",
        "        \n",
        "        # 2 hidden layers encoder\n",
        "        # Old dimension for MNIST\n",
        "        # self.fc_e0 = nn.Linear(784, h_dim * 2)\n",
        "        # New dimension of input\n",
        "        self.fc_e0 = nn.Linear(32738, h_dim * 2)\n",
        "        self.fc_e1 = nn.Linear(h_dim * 2, h_dim)\n",
        "\n",
        "        if self.distribution == 'normal':\n",
        "            # compute mean and std of the normal distribution\n",
        "            self.fc_mean = nn.Linear(h_dim, z_dim)\n",
        "            self.fc_var =  nn.Linear(h_dim, z_dim)\n",
        "        elif self.distribution == 'vmf':\n",
        "            # compute mean and concentration of the von Mises-Fisher\n",
        "            self.fc_mean = nn.Linear(h_dim, z_dim)\n",
        "            self.fc_var = nn.Linear(h_dim, 1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "            \n",
        "        # 2 hidden layers decoder\n",
        "        self.fc_d0 = nn.Linear(z_dim, h_dim)\n",
        "        self.fc_d1 = nn.Linear(h_dim, h_dim * 2)\n",
        "        # Old dimension for MNIST\n",
        "        # self.fc_logits = nn.Linear(h_dim * 2, 784)\n",
        "        # New dimension of input\n",
        "        self.fc_logits = nn.Linear(h_dim * 2, 32738)\n",
        "        self.mu_layer = nn.Linear(h_dim * 2, 32738)\n",
        "        self.var_layer = nn.Linear(h_dim * 2, 32738)\n",
        "\n",
        "        # self.library_size = torch.sum(x[0: 64,:], dim=1, keepdim=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # 2 hidden layers encoder\n",
        "        x = self.activation(self.fc_e0(x))\n",
        "        x = self.activation(self.fc_e1(x))\n",
        "        \n",
        "        if self.distribution == 'normal':\n",
        "            # compute mean and std of the normal distribution\n",
        "            z_mean = self.fc_mean(x)\n",
        "            z_var = F.softplus(self.fc_var(x))\n",
        "        elif self.distribution == 'vmf':\n",
        "            # compute mean and concentration of the von Mises-Fisher\n",
        "            z_mean = self.fc_mean(x)\n",
        "            z_mean = z_mean / z_mean.norm(dim=-1, keepdim=True)\n",
        "            # the `+ 1` prevent collapsing behaviors\n",
        "            z_var = F.softplus(self.fc_var(x)) + 1\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "        \n",
        "        return z_mean, z_var\n",
        "        \n",
        "    def decode(self, z):\n",
        "        \n",
        "        x = self.activation(self.fc_d0(z))\n",
        "        x = self.activation(self.fc_d1(x))\n",
        "        # x = self.fc_logits(x)\n",
        "        mu = F.softmax(self.mu_layer(x))\n",
        "        sigma_square = F.softplus(self.var_layer(x))\n",
        "        sigma_square = torch.sum(sigma_square, dim=0)\n",
        "        return mu, sigma_square\n",
        "        \n",
        "    def reparameterize(self, z_mean, z_var):\n",
        "        if self.distribution == 'normal':\n",
        "            q_z = torch.distributions.normal.Normal(z_mean, z_var)\n",
        "            p_z = torch.distributions.normal.Normal(torch.zeros_like(z_mean), torch.ones_like(z_var))\n",
        "        elif self.distribution == 'vmf':\n",
        "            q_z = VonMisesFisher(z_mean, z_var)\n",
        "            p_z = HypersphericalUniform(self.z_dim - 1)\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "\n",
        "        return q_z, p_z\n",
        "        \n",
        "    def forward(self, x): \n",
        "        z_mean, z_var = self.encode(x)\n",
        "        q_z, p_z = self.reparameterize(z_mean, z_var)\n",
        "        z = q_z.rsample()\n",
        "        # x_ = self.decode(z)\n",
        "        mu_, sigma_square_ = self.decode(z)\n",
        "        return (z_mean, z_var), (q_z, p_z), z, mu_, sigma_square_"
      ],
      "metadata": {
        "id": "WXxvQsN9zYPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood(model, x, n=10):\n",
        "    \"\"\"\n",
        "    :param model: model object\n",
        "    :param optimizer: optimizer object\n",
        "    :param n: number of MC samples\n",
        "    :return: MC estimate of log-likelihood\n",
        "    \"\"\"\n",
        "    # Old dimension for MNIST\n",
        "    # z_mean, z_var = model.encode(x.reshape(-1, 784))\n",
        "    z_mean, z_var = model.encode(x)\n",
        "    q_z, p_z = model.reparameterize(z_mean, z_var)\n",
        "    z = q_z.rsample(torch.Size([n]))\n",
        "    x_mb_ = model.decode(z)\n",
        "\n",
        "    log_p_z = p_z.log_prob(z)\n",
        "\n",
        "    if model.distribution == 'normal':\n",
        "        log_p_z = log_p_z.sum(-1)\n",
        "\n",
        "    log_p_x_z = -nn.BCEWithLogitsLoss(reduction='none')(x_mb_, x.reshape(-1, 784).repeat((n, 1, 1))).sum(-1)\n",
        "\n",
        "    log_q_z_x = q_z.log_prob(z)\n",
        "\n",
        "    if model.distribution == 'normal':\n",
        "        log_q_z_x = log_q_z_x.sum(-1)\n",
        "\n",
        "    return ((log_p_x_z + log_p_z - log_q_z_x).t().logsumexp(-1) - np.log(n)).mean()"
      ],
      "metadata": {
        "id": "gke1WXT5160W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_likelihood_nb(x, mu, sigma, eps=1e-16):\n",
        "\n",
        "    log_mu_sigma = torch.log(mu + sigma + eps)\n",
        "\n",
        "    ll = torch.lgamma(x + sigma) - torch.lgamma(sigma) - \\\n",
        "        torch.lgamma(x + 1) + sigma * torch.log(sigma + eps) - \\\n",
        "        sigma * log_mu_sigma + x * torch.log(mu + eps) - x * log_mu_sigma\n",
        "\n",
        "    return ll"
      ],
      "metadata": {
        "id": "dCVaZl4R3g9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library_size = None\n",
        "def train(model, optimizer):\n",
        "    # for i, (x_mb, y_mb) in enumerate(train_loader):\n",
        "    for i in range(0, X.shape[0], 64):\n",
        "    # for x in X:\n",
        "            if i+64 < X.shape[0]:\n",
        "              x = X[i: i+64, :]\n",
        "            else:\n",
        "              x = X[i:, :]\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # dynamic binarization\n",
        "            # x_mb = (x_mb > torch.distributions.Uniform(0, 1).sample(x_mb.shape)).float()\n",
        "\n",
        "            # _, (q_z, p_z), _, x_mb_ = model(x_mb.reshape(-1, 784))\n",
        "            global library_size\n",
        "            library_size = torch.sum(x, dim=1, keepdim=True)\n",
        "            (z_mean, z_var), (q_z, p_z), _, mu, sigma_square = model(x)\n",
        "            # loss_recon = nn.BCEWithLogitsLoss(reduction='none')(x_reconstructed, x).sum(-1).mean()\n",
        "            # loss_recon = log_likelihood(x, z_mean, z_var)\n",
        "            mu = mu * library_size\n",
        "            loss_recon = log_likelihood_nb(\n",
        "                x,\n",
        "                mu,\n",
        "                sigma_square,\n",
        "            ).sum(-1).mean()\n",
        "          \n",
        "            if model.distribution == 'normal':\n",
        "                loss_KL = torch.distributions.kl.kl_divergence(q_z, p_z).sum(-1).mean()\n",
        "            elif model.distribution == 'vmf':\n",
        "                loss_KL = torch.distributions.kl.kl_divergence(q_z, p_z).mean()\n",
        "            else:\n",
        "                raise NotImplemented\n",
        "\n",
        "            loss = loss_recon + loss_KL\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "eF8UqZkH2vnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden dimension and dimension of latent space\n",
        "H_DIM = 128\n",
        "Z_DIM = 5\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "# normal VAE\n",
        "modelN = ModelVAE(h_dim=H_DIM, z_dim=Z_DIM, distribution='normal', x=X)\n",
        "optimizerN = optim.Adam(modelN.parameters(), lr=1e-3)\n",
        "\n",
        "print('##### Normal VAE #####')\n",
        "\n",
        "# training for 1 epoch\n",
        "train(modelN, optimizerN)\n",
        "\n",
        "# test\n",
        "# test(modelN, optimizerN)\n",
        "\n",
        "print()\n",
        "\n",
        "# hyper-spherical  VAE\n",
        "modelS = ModelVAE(h_dim=H_DIM, z_dim=Z_DIM + 1, distribution='vmf')\n",
        "optimizerS = optim.Adam(modelS.parameters(), lr=1e-3)\n",
        "\n",
        "print('##### Hyper-spherical VAE #####')\n",
        "\n",
        "# training for 1 epoch\n",
        "train(modelS, optimizerS)\n",
        "\n",
        "# test\n",
        "# test(modelS, optimizerS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ZW8lsRAnFj",
        "outputId": "bc57e49e-bd63-4e73-947b-1c4b675f80b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Normal VAE #####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-71ac4c9d4f99>:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  mu = F.softmax(self.mu_layer(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##### Hyper-spherical VAE #####\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/distributions/distribution.py:51: UserWarning: <class 'hyperspherical_vae.distributions.hyperspherical_uniform.HypersphericalUniform'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  warnings.warn(f'{self.__class__} does not define `arg_constraints`. ' +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byueprTFBDp6",
        "outputId": "956dfc67-2da4-4f91-ff8c-7030885cf85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}